{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alzheimer's Disease Detection from Brain MRI Scans\n",
    "\n",
    "## Deep Learning Classification using EfficientNet\n",
    "\n",
    "**Author:** Hack4Health Team  \n",
    "**Date:** December 2025\n",
    "\n",
    "---\n",
    "\n",
    "### Overview\n",
    "\n",
    "This notebook implements an AI model for early detection of Alzheimer's disease using brain MRI scans. We use transfer learning with EfficientNet-B0 to classify MRI images into four categories:\n",
    "\n",
    "1. **NonDemented** - Healthy brain with no signs of dementia\n",
    "2. **VeryMildDemented** - Very early stage Alzheimer's\n",
    "3. **MildDemented** - Mild cognitive impairment\n",
    "4. **ModerateDemented** - Moderate stage Alzheimer's\n",
    "\n",
    "### Key Features\n",
    "- Transfer learning with pre-trained EfficientNet-B0\n",
    "- Data augmentation for improved generalization\n",
    "- Weighted loss function to handle class imbalance\n",
    "- Grad-CAM visualizations for model interpretability\n",
    "- Comprehensive evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies if running in Google Colab\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    !pip install -q torch torchvision\n",
    "    !pip install -q opencv-python-headless\n",
    "    print(\"Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torchvision import transforms, models\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score\n",
    ")\n",
    "\n",
    "# Progress bar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# OpenCV for Grad-CAM\n",
    "import cv2\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('viridis')\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"MPS available: {torch.backends.mps.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Select device\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device('mps')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "class Config:\n",
    "    # Paths\n",
    "    DATA_DIR = '../data/Alzheimer_MRI_4_classes_dataset'\n",
    "    SAVE_DIR = '../checkpoints'\n",
    "    \n",
    "    # Model\n",
    "    MODEL_NAME = 'efficientnet'  # 'efficientnet', 'resnet', or 'baseline'\n",
    "    NUM_CLASSES = 4\n",
    "    PRETRAINED = True\n",
    "    \n",
    "    # Training\n",
    "    BATCH_SIZE = 32\n",
    "    NUM_EPOCHS = 20\n",
    "    LEARNING_RATE = 1e-4\n",
    "    WEIGHT_DECAY = 1e-4\n",
    "    \n",
    "    # Data\n",
    "    IMAGE_SIZE = 224\n",
    "    TEST_SIZE = 0.15\n",
    "    VAL_SIZE = 0.15\n",
    "    NUM_WORKERS = 0  # Set to 0 for compatibility\n",
    "    \n",
    "    # Early stopping\n",
    "    PATIENCE = 7\n",
    "    \n",
    "    # Class names\n",
    "    CLASS_NAMES = ['MildDemented', 'ModerateDemented', 'NonDemented', 'VeryMildDemented']\n",
    "\n",
    "config = Config()\n",
    "\n",
    "# Create save directory\n",
    "os.makedirs(config.SAVE_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Configuration loaded!\")\n",
    "print(f\"Data directory: {config.DATA_DIR}\")\n",
    "print(f\"Model: {config.MODEL_NAME}\")\n",
    "print(f\"Batch size: {config.BATCH_SIZE}\")\n",
    "print(f\"Epochs: {config.NUM_EPOCHS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset paths and labels\n",
    "def load_dataset(data_dir):\n",
    "    \"\"\"Load all image paths and labels from the dataset directory.\"\"\"\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    class_to_idx = {name: idx for idx, name in enumerate(config.CLASS_NAMES)}\n",
    "    \n",
    "    data_path = Path(data_dir)\n",
    "    \n",
    "    for class_name in config.CLASS_NAMES:\n",
    "        class_dir = data_path / class_name\n",
    "        if not class_dir.exists():\n",
    "            print(f\"Warning: {class_dir} does not exist\")\n",
    "            continue\n",
    "        \n",
    "        class_idx = class_to_idx[class_name]\n",
    "        \n",
    "        for img_file in class_dir.iterdir():\n",
    "            if img_file.suffix.lower() in ['.jpg', '.jpeg', '.png']:\n",
    "                image_paths.append(str(img_file))\n",
    "                labels.append(class_idx)\n",
    "    \n",
    "    return image_paths, labels\n",
    "\n",
    "# Load data\n",
    "image_paths, labels = load_dataset(config.DATA_DIR)\n",
    "print(f\"Total images found: {len(image_paths)}\")\n",
    "\n",
    "# Class distribution\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "print(\"\\nClass distribution:\")\n",
    "for idx, count in zip(unique, counts):\n",
    "    print(f\"  {config.CLASS_NAMES[idx]}: {count} images ({100*count/len(labels):.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "colors = plt.cm.viridis(np.linspace(0.2, 0.8, len(config.CLASS_NAMES)))\n",
    "\n",
    "bars = ax.bar(config.CLASS_NAMES, counts, color=colors, edgecolor='black', linewidth=1.5)\n",
    "\n",
    "for bar, count in zip(bars, counts):\n",
    "    height = bar.get_height()\n",
    "    ax.annotate(f'{count}\\n({100*count/len(labels):.1f}%)',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 5), textcoords='offset points',\n",
    "                ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "ax.set_xlabel('Dementia Stage', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Number of Images', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Dataset Class Distribution\\n(Alzheimer\\'s MRI Images)', fontsize=14, fontweight='bold')\n",
    "ax.tick_params(axis='x', rotation=15)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../checkpoints/class_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n⚠️ Note: Significant class imbalance detected (ModerateDemented has very few samples)\")\n",
    "print(\"   We will use weighted loss and weighted sampling to address this.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images from each class\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "samples_per_class = 2\n",
    "idx = 0\n",
    "\n",
    "for class_idx, class_name in enumerate(config.CLASS_NAMES):\n",
    "    class_images = [p for p, l in zip(image_paths, labels) if l == class_idx]\n",
    "    \n",
    "    for i in range(min(samples_per_class, len(class_images))):\n",
    "        img = Image.open(class_images[i]).convert('RGB')\n",
    "        axes[idx].imshow(img, cmap='gray')\n",
    "        axes[idx].set_title(f'{class_name}', fontsize=11, fontweight='bold')\n",
    "        axes[idx].axis('off')\n",
    "        idx += 1\n",
    "\n",
    "plt.suptitle('Sample MRI Images from Each Dementia Stage', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../checkpoints/sample_images.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing and Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageNet normalization values (for pre-trained models)\n",
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Training transforms with augmentation\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((config.IMAGE_SIZE, config.IMAGE_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=MEAN, std=STD)\n",
    "])\n",
    "\n",
    "# Validation/Test transforms (no augmentation)\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((config.IMAGE_SIZE, config.IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=MEAN, std=STD)\n",
    "])\n",
    "\n",
    "print(\"Transforms defined!\")\n",
    "print(\"\\nTraining augmentations:\")\n",
    "print(\"  - Random horizontal flip\")\n",
    "print(\"  - Random rotation (±15°)\")\n",
    "print(\"  - Random translation (±10%)\")\n",
    "print(\"  - Color jitter (brightness, contrast)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset class\n",
    "class AlzheimerMRIDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for Alzheimer's MRI images.\"\"\"\n",
    "    \n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "print(\"Dataset class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/val/test splits\n",
    "# First split: separate test set\n",
    "train_val_paths, test_paths, train_val_labels, test_labels = train_test_split(\n",
    "    image_paths, labels,\n",
    "    test_size=config.TEST_SIZE,\n",
    "    stratify=labels,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Second split: separate validation from training\n",
    "val_ratio = config.VAL_SIZE / (1 - config.TEST_SIZE)\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "    train_val_paths, train_val_labels,\n",
    "    test_size=val_ratio,\n",
    "    stratify=train_val_labels,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nDataset splits:\")\n",
    "print(f\"  Training:   {len(train_paths)} images ({100*len(train_paths)/len(image_paths):.1f}%)\")\n",
    "print(f\"  Validation: {len(val_paths)} images ({100*len(val_paths)/len(image_paths):.1f}%)\")\n",
    "print(f\"  Test:       {len(test_paths)} images ({100*len(test_paths)/len(image_paths):.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = AlzheimerMRIDataset(train_paths, train_labels, transform=train_transforms)\n",
    "val_dataset = AlzheimerMRIDataset(val_paths, val_labels, transform=val_transforms)\n",
    "test_dataset = AlzheimerMRIDataset(test_paths, test_labels, transform=val_transforms)\n",
    "\n",
    "print(f\"Datasets created!\")\n",
    "print(f\"  Train: {len(train_dataset)} samples\")\n",
    "print(f\"  Val:   {len(val_dataset)} samples\")\n",
    "print(f\"  Test:  {len(test_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights for handling imbalance\n",
    "class_counts = np.bincount(train_labels, minlength=config.NUM_CLASSES)\n",
    "total_samples = len(train_labels)\n",
    "class_weights = total_samples / (config.NUM_CLASSES * class_counts + 1e-6)\n",
    "class_weights = torch.FloatTensor(class_weights).to(DEVICE)\n",
    "\n",
    "print(\"Class weights for loss function:\")\n",
    "for i, name in enumerate(config.CLASS_NAMES):\n",
    "    print(f\"  {name}: {class_weights[i]:.3f}\")\n",
    "\n",
    "# Create weighted sampler for training\n",
    "sample_weights = [class_weights[label].item() for label in train_labels]\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=sample_weights,\n",
    "    num_samples=len(train_labels),\n",
    "    replacement=True\n",
    ")\n",
    "\n",
    "print(\"\\nWeighted sampler created for balanced training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.BATCH_SIZE,\n",
    "    sampler=sampler,\n",
    "    num_workers=config.NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config.BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=config.NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=config.BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=config.NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"DataLoaders created!\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches:   {len(val_loader)}\")\n",
    "print(f\"  Test batches:  {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlzheimerEfficientNet(nn.Module):\n",
    "    \"\"\"\n",
    "    EfficientNet-B0 based model for Alzheimer's classification.\n",
    "    Uses transfer learning with a custom classification head.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=4, dropout=0.3, pretrained=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Load pretrained EfficientNet-B0\n",
    "        if pretrained:\n",
    "            weights = models.EfficientNet_B0_Weights.IMAGENET1K_V1\n",
    "            self.backbone = models.efficientnet_b0(weights=weights)\n",
    "        else:\n",
    "            self.backbone = models.efficientnet_b0(weights=None)\n",
    "        \n",
    "        # Get the number of features from the backbone\n",
    "        num_features = self.backbone.classifier[1].in_features\n",
    "        \n",
    "        # Replace the classifier with custom head\n",
    "        self.backbone.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=dropout, inplace=True),\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout / 2),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "# Create model\n",
    "model = AlzheimerEfficientNet(\n",
    "    num_classes=config.NUM_CLASSES,\n",
    "    dropout=0.3,\n",
    "    pretrained=config.PRETRAINED\n",
    ").to(DEVICE)\n",
    "\n",
    "# Model summary\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Architecture: EfficientNet-B0 (Transfer Learning)\")\n",
    "print(f\"Total Parameters:     {total_params:,}\")\n",
    "print(f\"Trainable Parameters: {trainable_params:,}\")\n",
    "print(f\"Output Classes:       {config.NUM_CLASSES}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function with class weights\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=config.LEARNING_RATE,\n",
    "    weight_decay=config.WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"Training setup complete!\")\n",
    "print(f\"  Optimizer: AdamW (lr={config.LEARNING_RATE}, weight_decay={config.WEIGHT_DECAY})\")\n",
    "print(f\"  Scheduler: ReduceLROnPlateau (factor=0.5, patience=3)\")\n",
    "print(f\"  Loss: CrossEntropyLoss (weighted)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping class\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, min_delta=0.001):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "        self.best_model_state = None\n",
    "    \n",
    "    def __call__(self, val_loss, model):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_model_state = model.state_dict().copy()\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            print(f'  EarlyStopping counter: {self.counter}/{self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_model_state = model.state_dict().copy()\n",
    "            self.counter = 0\n",
    "        return self.early_stop\n",
    "\n",
    "early_stopping = EarlyStopping(patience=config.PATIENCE)\n",
    "print(f\"Early stopping initialized (patience={config.PATIENCE})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(loader, desc='Training', leave=False)\n",
    "    \n",
    "    for images, labels in pbar:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}', 'acc': f'{100.*correct/total:.2f}%'})\n",
    "    \n",
    "    return running_loss / total, 100. * correct / total\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, loader, criterion, device):\n",
    "    \"\"\"Validate the model.\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in tqdm(loader, desc='Validating', leave=False):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    return running_loss / total, 100. * correct / total\n",
    "\n",
    "print(\"Training functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': [],\n",
    "    'lr': []\n",
    "}\n",
    "\n",
    "best_val_acc = 0.0\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for epoch in range(config.NUM_EPOCHS):\n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, DEVICE)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion, DEVICE)\n",
    "    \n",
    "    # Get learning rate\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Update history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['lr'].append(current_lr)\n",
    "    \n",
    "    # Update scheduler\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Print progress\n",
    "    print(f\"\\nEpoch [{epoch+1}/{config.NUM_EPOCHS}]\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"  Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.2f}%\")\n",
    "    print(f\"  LR: {current_lr:.6f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "            'val_loss': val_loss,\n",
    "        }, f'{config.SAVE_DIR}/best_model.pth')\n",
    "        print(f\"  ✓ Saved best model (val_acc: {val_acc:.2f}%)\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if early_stopping(val_loss, model):\n",
    "        print(f\"\\n⚠️ Early stopping triggered at epoch {epoch+1}\")\n",
    "        model.load_state_dict(early_stopping.best_model_state)\n",
    "        break\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"Training completed! Best validation accuracy: {best_val_acc:.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "epochs = range(1, len(history['train_loss']) + 1)\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(epochs, history['train_loss'], 'b-', label='Train', linewidth=2)\n",
    "axes[0].plot(epochs, history['val_loss'], 'r-', label='Validation', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch', fontweight='bold')\n",
    "axes[0].set_ylabel('Loss', fontweight='bold')\n",
    "axes[0].set_title('Training and Validation Loss', fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[1].plot(epochs, history['train_acc'], 'b-', label='Train', linewidth=2)\n",
    "axes[1].plot(epochs, history['val_acc'], 'r-', label='Validation', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch', fontweight='bold')\n",
    "axes[1].set_ylabel('Accuracy (%)', fontweight='bold')\n",
    "axes[1].set_title('Training and Validation Accuracy', fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Learning Rate\n",
    "axes[2].plot(epochs, history['lr'], 'g-', linewidth=2)\n",
    "axes[2].set_xlabel('Epoch', fontweight='bold')\n",
    "axes[2].set_ylabel('Learning Rate', fontweight='bold')\n",
    "axes[2].set_title('Learning Rate Schedule', fontweight='bold')\n",
    "axes[2].set_yscale('log')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../checkpoints/training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "checkpoint = torch.load(f'{config.SAVE_DIR}/best_model.pth', map_location=DEVICE)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"Loaded best model from epoch {checkpoint['epoch']+1} (val_acc: {checkpoint['val_acc']:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions on test set\n",
    "@torch.no_grad()\n",
    "def get_predictions(model, loader, device):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    \n",
    "    for images, labels in tqdm(loader, desc='Evaluating'):\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        _, preds = outputs.max(1)\n",
    "        \n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_probs.extend(probs.cpu().numpy())\n",
    "    \n",
    "    return np.array(all_labels), np.array(all_preds), np.array(all_probs)\n",
    "\n",
    "y_true, y_pred, y_prob = get_predictions(model, test_loader, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TEST SET EVALUATION METRICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "precision = precision_score(y_true, y_pred, average='macro', zero_division=0) * 100\n",
    "recall = recall_score(y_true, y_pred, average='macro', zero_division=0) * 100\n",
    "f1 = f1_score(y_true, y_pred, average='macro', zero_division=0) * 100\n",
    "\n",
    "print(f\"\\nOverall Metrics:\")\n",
    "print(f\"  Accuracy:          {accuracy:.2f}%\")\n",
    "print(f\"  Precision (macro): {precision:.2f}%\")\n",
    "print(f\"  Recall (macro):    {recall:.2f}%\")\n",
    "print(f\"  F1 Score (macro):  {f1:.2f}%\")\n",
    "\n",
    "# AUC\n",
    "try:\n",
    "    auc = roc_auc_score(y_true, y_prob, multi_class='ovr', average='macro') * 100\n",
    "    print(f\"  AUC (macro):       {auc:.2f}%\")\n",
    "except:\n",
    "    auc = None\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Classification Report:\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_true, y_pred, target_names=config.CLASS_NAMES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Raw counts\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=config.CLASS_NAMES, yticklabels=config.CLASS_NAMES,\n",
    "            ax=axes[0], annot_kws={'size': 12})\n",
    "axes[0].set_xlabel('Predicted', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('True', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Confusion Matrix (Counts)', fontsize=14, fontweight='bold')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "axes[0].tick_params(axis='y', rotation=0)\n",
    "\n",
    "# Normalized\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.1%', cmap='Blues',\n",
    "            xticklabels=config.CLASS_NAMES, yticklabels=config.CLASS_NAMES,\n",
    "            ax=axes[1], annot_kws={'size': 12})\n",
    "axes[1].set_xlabel('Predicted', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('True', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('Confusion Matrix (Normalized)', fontsize=14, fontweight='bold')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "axes[1].tick_params(axis='y', rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../checkpoints/confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model Interpretability (Grad-CAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradCAM:\n",
    "    \"\"\"Grad-CAM implementation for model interpretability.\"\"\"\n",
    "    \n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        \n",
    "        # Register hooks\n",
    "        target_layer.register_forward_hook(self._forward_hook)\n",
    "        target_layer.register_full_backward_hook(self._backward_hook)\n",
    "    \n",
    "    def _forward_hook(self, module, input, output):\n",
    "        self.activations = output.detach()\n",
    "    \n",
    "    def _backward_hook(self, module, grad_input, grad_output):\n",
    "        self.gradients = grad_output[0].detach()\n",
    "    \n",
    "    def generate(self, input_tensor, target_class=None):\n",
    "        self.model.eval()\n",
    "        output = self.model(input_tensor)\n",
    "        \n",
    "        if target_class is None:\n",
    "            target_class = output.argmax(dim=1).item()\n",
    "        \n",
    "        self.model.zero_grad()\n",
    "        one_hot = torch.zeros_like(output)\n",
    "        one_hot[0, target_class] = 1\n",
    "        output.backward(gradient=one_hot, retain_graph=True)\n",
    "        \n",
    "        gradients = self.gradients[0]\n",
    "        activations = self.activations[0]\n",
    "        \n",
    "        weights = gradients.mean(dim=(1, 2), keepdim=True)\n",
    "        cam = (weights * activations).sum(dim=0)\n",
    "        cam = torch.relu(cam)\n",
    "        cam = cam - cam.min()\n",
    "        cam = cam / (cam.max() + 1e-8)\n",
    "        \n",
    "        return cam.cpu().numpy()\n",
    "\n",
    "# Get the last convolutional layer of EfficientNet\n",
    "target_layer = model.backbone.features[-1]\n",
    "gradcam = GradCAM(model, target_layer)\n",
    "\n",
    "print(\"Grad-CAM initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to denormalize images\n",
    "def denormalize(tensor):\n",
    "    mean = np.array(MEAN)\n",
    "    std = np.array(STD)\n",
    "    image = tensor.cpu().numpy().transpose(1, 2, 0)\n",
    "    image = std * image + mean\n",
    "    image = np.clip(image, 0, 1)\n",
    "    return image\n",
    "\n",
    "# Visualize Grad-CAM for sample images\n",
    "num_samples = 8\n",
    "fig, axes = plt.subplots(num_samples, 3, figsize=(12, num_samples * 3))\n",
    "\n",
    "# Get sample images\n",
    "sample_images = []\n",
    "sample_labels = []\n",
    "for images, labels in test_loader:\n",
    "    for img, lbl in zip(images, labels):\n",
    "        sample_images.append(img)\n",
    "        sample_labels.append(lbl.item())\n",
    "        if len(sample_images) >= num_samples:\n",
    "            break\n",
    "    if len(sample_images) >= num_samples:\n",
    "        break\n",
    "\n",
    "for i, (img, true_label) in enumerate(zip(sample_images, sample_labels)):\n",
    "    img_tensor = img.unsqueeze(0).to(DEVICE)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(img_tensor)\n",
    "        pred_label = output.argmax(dim=1).item()\n",
    "    \n",
    "    # Generate Grad-CAM\n",
    "    cam = gradcam.generate(img_tensor, pred_label)\n",
    "    \n",
    "    # Denormalize image\n",
    "    original = denormalize(img)\n",
    "    \n",
    "    # Resize CAM\n",
    "    cam_resized = cv2.resize(cam, (original.shape[1], original.shape[0]))\n",
    "    \n",
    "    # Create heatmap\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * cam_resized), cv2.COLORMAP_JET)\n",
    "    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB) / 255.0\n",
    "    \n",
    "    # Overlay\n",
    "    overlay = 0.5 * original + 0.5 * heatmap\n",
    "    overlay = overlay / overlay.max()\n",
    "    \n",
    "    # Plot\n",
    "    axes[i, 0].imshow(original)\n",
    "    axes[i, 0].set_title(f'Original\\nTrue: {config.CLASS_NAMES[true_label]}', fontsize=10)\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    axes[i, 1].imshow(cam_resized, cmap='jet')\n",
    "    axes[i, 1].set_title('Grad-CAM Heatmap', fontsize=10)\n",
    "    axes[i, 1].axis('off')\n",
    "    \n",
    "    color = 'green' if pred_label == true_label else 'red'\n",
    "    axes[i, 2].imshow(overlay)\n",
    "    axes[i, 2].set_title(f'Overlay\\nPred: {config.CLASS_NAMES[pred_label]}', fontsize=10, color=color)\n",
    "    axes[i, 2].axis('off')\n",
    "\n",
    "plt.suptitle('Grad-CAM Visualizations: Where the Model Looks', fontsize=14, fontweight='bold', y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../checkpoints/gradcam_visualizations.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Sample Predictions Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "num_samples = 16\n",
    "fig, axes = plt.subplots(4, 4, figsize=(14, 14))\n",
    "axes = axes.flatten()\n",
    "\n",
    "sample_images = []\n",
    "sample_labels = []\n",
    "sample_preds = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(DEVICE)\n",
    "        outputs = model(images)\n",
    "        _, preds = outputs.max(1)\n",
    "        \n",
    "        for img, lbl, pred in zip(images, labels, preds):\n",
    "            sample_images.append(img.cpu())\n",
    "            sample_labels.append(lbl.item())\n",
    "            sample_preds.append(pred.item())\n",
    "            \n",
    "            if len(sample_images) >= num_samples:\n",
    "                break\n",
    "        if len(sample_images) >= num_samples:\n",
    "            break\n",
    "\n",
    "for i, (img, true_lbl, pred_lbl) in enumerate(zip(sample_images, sample_labels, sample_preds)):\n",
    "    original = denormalize(img)\n",
    "    axes[i].imshow(original)\n",
    "    \n",
    "    true_name = config.CLASS_NAMES[true_lbl]\n",
    "    pred_name = config.CLASS_NAMES[pred_lbl]\n",
    "    \n",
    "    color = 'green' if true_lbl == pred_lbl else 'red'\n",
    "    axes[i].set_title(f'True: {true_name}\\nPred: {pred_name}', fontsize=9, color=color, fontweight='bold')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Sample Predictions (Green=Correct, Red=Incorrect)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../checkpoints/sample_predictions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Model Card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_card = f\"\"\"\n",
    "================================================================================\n",
    "                              MODEL CARD\n",
    "================================================================================\n",
    "\n",
    "MODEL DETAILS\n",
    "--------------------------------------------------------------------------------\n",
    "Name:                    Alzheimer's MRI Classification Model\n",
    "Architecture:            EfficientNet-B0 (Transfer Learning)\n",
    "Framework:               PyTorch {torch.__version__}\n",
    "Total Parameters:        {total_params:,}\n",
    "Trainable Parameters:    {trainable_params:,}\n",
    "\n",
    "INTENDED USE\n",
    "--------------------------------------------------------------------------------\n",
    "Primary Use:             Research and educational purposes\n",
    "                         Assisting in early detection of Alzheimer's disease\n",
    "                         from brain MRI scans\n",
    "\n",
    "Users:                   Researchers, medical students, healthcare professionals\n",
    "                         (as a screening aid, NOT diagnostic tool)\n",
    "\n",
    "Out of Scope:            Direct clinical diagnosis without expert verification\n",
    "                         High-stakes medical decisions\n",
    "                         Deployment in production healthcare systems\n",
    "\n",
    "TRAINING DATA\n",
    "--------------------------------------------------------------------------------\n",
    "Dataset:                 Alzheimer's MRI 4-Classes Dataset\n",
    "Total Images:            {len(image_paths)}\n",
    "Classes:                 4 (NonDemented, VeryMildDemented, MildDemented, ModerateDemented)\n",
    "Training Set:            {len(train_paths)} images\n",
    "Validation Set:          {len(val_paths)} images  \n",
    "Test Set:                {len(test_paths)} images\n",
    "\n",
    "PERFORMANCE METRICS (Test Set)\n",
    "--------------------------------------------------------------------------------\n",
    "Accuracy:                {accuracy:.2f}%\n",
    "Precision (macro):       {precision:.2f}%\n",
    "Recall (macro):          {recall:.2f}%\n",
    "F1 Score (macro):        {f1:.2f}%\n",
    "{f'AUC (macro):            {auc:.2f}%' if auc else ''}\n",
    "\n",
    "LIMITATIONS AND BIASES\n",
    "--------------------------------------------------------------------------------\n",
    "1. Dataset Imbalance:    ModerateDemented class has very few samples (64),\n",
    "                         which may affect model performance on this class.\n",
    "\n",
    "2. Dataset Source:       Model trained on a specific dataset; may not\n",
    "                         generalize well to MRI images from different\n",
    "                         scanners, protocols, or populations.\n",
    "\n",
    "3. 2D Slices Only:       Model analyzes individual 2D MRI slices, not\n",
    "                         full 3D brain volumes, limiting anatomical context.\n",
    "\n",
    "4. No Clinical Validation: This model has NOT been validated in clinical\n",
    "                         settings and should NOT be used for diagnosis.\n",
    "\n",
    "5. Demographic Bias:     Dataset demographics unknown; model may not\n",
    "                         perform equally across all demographic groups.\n",
    "\n",
    "ETHICAL CONSIDERATIONS\n",
    "--------------------------------------------------------------------------------\n",
    "- AI-assisted diagnosis should always be verified by qualified healthcare\n",
    "  professionals\n",
    "- False positives could cause unnecessary anxiety; false negatives could\n",
    "  delay treatment\n",
    "- Patient consent and data privacy must be maintained\n",
    "- Model decisions should be explainable (Grad-CAM provided for transparency)\n",
    "\n",
    "RECOMMENDATIONS\n",
    "--------------------------------------------------------------------------------\n",
    "1. Use as screening aid only, not as diagnostic tool\n",
    "2. Always verify predictions with medical professionals\n",
    "3. Fine-tune on local hospital data before any clinical use\n",
    "4. Conduct thorough bias and fairness testing before deployment\n",
    "5. Implement proper model monitoring in production\n",
    "\n",
    "================================================================================\n",
    "\"\"\"\n",
    "\n",
    "print(model_card)\n",
    "\n",
    "# Save model card\n",
    "with open('../checkpoints/model_card.txt', 'w') as f:\n",
    "    f.write(model_card)\n",
    "print(\"Model card saved to ../checkpoints/model_card.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "================================================================================\n",
    "                         PROJECT SUMMARY\n",
    "================================================================================\n",
    "\n",
    "OBJECTIVE\n",
    "--------------------------------------------------------------------------------\n",
    "Built an AI model for early detection of Alzheimer's disease using brain MRI\n",
    "scans, classifying images into 4 stages of dementia.\n",
    "\n",
    "APPROACH\n",
    "--------------------------------------------------------------------------------\n",
    "1. Transfer Learning: Leveraged EfficientNet-B0 pre-trained on ImageNet\n",
    "2. Data Augmentation: Applied rotation, flipping, and color jitter\n",
    "3. Class Imbalance Handling: Used weighted loss and weighted sampling\n",
    "4. Regularization: Dropout, early stopping, learning rate scheduling\n",
    "\n",
    "KEY RESULTS\n",
    "--------------------------------------------------------------------------------\n",
    "\"\"\")\n",
    "print(f\"- Test Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"- F1 Score (macro): {f1:.2f}%\")\n",
    "print(f\"- Best model saved at epoch with val_acc: {checkpoint['val_acc']:.2f}%\")\n",
    "\n",
    "print(\"\"\"\n",
    "DELIVERABLES\n",
    "--------------------------------------------------------------------------------\n",
    "1. ✓ Reproducible Jupyter Notebook (this file)\n",
    "2. ✓ Trained Model (../checkpoints/best_model.pth)\n",
    "3. ✓ Training History Plots\n",
    "4. ✓ Confusion Matrix\n",
    "5. ✓ Grad-CAM Visualizations (Model Interpretability)\n",
    "6. ✓ Model Card (../checkpoints/model_card.txt)\n",
    "\n",
    "FUTURE IMPROVEMENTS\n",
    "--------------------------------------------------------------------------------\n",
    "1. Collect more data for the underrepresented ModerateDemented class\n",
    "2. Experiment with 3D convolutional networks for volumetric MRI\n",
    "3. Implement ensemble methods for improved robustness\n",
    "4. Add uncertainty quantification for clinical reliability\n",
    "5. Validate on external datasets from different institutions\n",
    "\n",
    "================================================================================\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Notebook execution complete!\")\n",
    "print(f\"\\nAll outputs saved to: {config.SAVE_DIR}\")\n",
    "print(\"\\nFiles generated:\")\n",
    "for f in os.listdir(config.SAVE_DIR):\n",
    "    print(f\"  - {f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
